{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras implementation of Brain CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_DIM = 64\n",
    "SNAPS = 8 ##Number of snaps over 4 seconds\n",
    "STRIP_DEPTH = 8\n",
    "STRIP_WIDTH = IMG_DIM * SNAPS\n",
    "STRIP_HEIGHT = IMG_DIM * STRIP_DEPTH\n",
    "SLICE = 1\n",
    "CHANNELS = 1\n",
    "CLASSES = 2\n",
    "conv1_filter = 4\n",
    "conv2_filter = 4\n",
    "conv3_filter = 4\n",
    "conv4_filter = 4\n",
    "conv5_filter = 4\n",
    "conv6_filter = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment = '8snap'\n",
    "path = '/work/aaung/datasets/' + experiment + '/'\n",
    "\n",
    "_04847_img = np.load(path + '4847_' + experiment + '-image.npy')\n",
    "_04799_img = np.load(path + '4799_' + experiment + '-image.npy')\n",
    "_04820_img = np.load(path + '4820_' + experiment + '-image.npy')\n",
    "_05675_img = np.load(path + '5675_' + experiment + '-image.npy')\n",
    "_05680_img = np.load(path + '5680_' + experiment + '-image.npy')\n",
    "_05710_img = np.load(path + '5710_' + experiment + '-image.npy')\n",
    "\n",
    "_04847_lbl = np.load(path + '4847_' + experiment + '-label-onehot.npy')\n",
    "_04799_lbl = np.load(path + '4799_' + experiment + '-label-onehot.npy')\n",
    "_04820_lbl = np.load(path + '4820_' + experiment + '-label-onehot.npy')\n",
    "_05675_lbl = np.load(path + '5675_' + experiment + '-label-onehot.npy')\n",
    "_05680_lbl = np.load(path + '5680_' + experiment + '-label-onehot.npy')\n",
    "_05710_lbl = np.load(path + '5710_' + experiment + '-label-onehot.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave on example out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_img = np.vstack((_04847_img[5:,], _04799_img[5:,], _04820_img[5:,], _05675_img[5:,], _05680_img[5:,]))\n",
    "# train_lbl = np.vstack((_04847_lbl[5:,], _04799_lbl[5:,], _04820_lbl[5:,], _05675_lbl[5:,], _05680_lbl[5:,]))\n",
    "# val_img = np.vstack((_04847_img[:5,], _04799_img[:5,], _04820_img[:5,], _05675_img[:5,], _05680_img[:5,]))\n",
    "# val_lbl = np.vstack((_04847_lbl[:5,], _04799_lbl[:5,], _04820_lbl[:5,], _05675_lbl[:5,], _05680_lbl[:5,]))\n",
    "\n",
    "n = 10\n",
    "train_img = np.vstack((_04847_img[n:,], _04799_img[n:,], _04820_img[n:,], _05675_img[n:,], _05680_img[n:,], _05710_img[n:,]))\n",
    "train_lbl = np.vstack((_04847_lbl[n:,], _04799_lbl[n:,], _04820_lbl[n:,], _05675_lbl[n:,], _05680_lbl[n:,], _05710_lbl[n:,]))\n",
    "val_img = np.vstack((_04847_img[:n,], _04799_img[:n,], _04820_img[:n,], _05675_img[:n,], _05680_img[:n,], _05710_img[:n,]))\n",
    "val_lbl = np.vstack((_04847_lbl[:n,], _04799_lbl[:n,], _04820_lbl[:n,], _05675_lbl[:n,], _05680_lbl[:n,], _05710_lbl[:n,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_img[1,:,:])\n",
    "print train_img[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "# shuffle = np.random.permutation(database.shape[0])\n",
    "\n",
    "# test = database[shuffle[0:100],:]\n",
    "# val = database[shuffle[100:200],:]\n",
    "# train = database[shuffle[200:],:]\n",
    "\n",
    "xtrain = np.reshape(train_img, (train_img.shape[0], train_img.shape[1], train_img.shape[2], 1))\n",
    "ytrain = train_lbl\n",
    "\n",
    "xval = np.reshape(val_img, (val_img.shape[0], val_img.shape[1], val_img.shape[2], 1))\n",
    "yval = val_lbl\n",
    "\n",
    "### Model ###                                                                                                                               \n",
    "model = Sequential()\n",
    "mde = 0                                                                                                                                                                      \n",
    "k_init = 'he_normal'\n",
    "ridge = 0.0001\n",
    "\n",
    "model.add(Convolution2D(conv1_filter, kernel_size=(3, 3), strides=(1, 1),\n",
    "                        padding='same', data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                        kernel_regularizer=l2(ridge),\n",
    "                        kernel_initializer=k_init, bias_initializer='zeros', input_shape=(STRIP_HEIGHT, STRIP_WIDTH, CHANNELS)))                                                                                                   \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(conv2_filter, kernel_size=(5, 5), strides=(1, 1),\n",
    "                        padding='same', data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                        kernel_regularizer=l2(ridge),\n",
    "                        kernel_initializer=k_init, bias_initializer='zeros'))                                                                                                   \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "model.add(Convolution2D(conv3_filter, kernel_size=(7, 7), strides=(1, 1),\n",
    "                        padding='same', data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                        kernel_regularizer=l2(ridge),\n",
    "                        kernel_initializer=k_init, bias_initializer='zeros'))                                                                                                   \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(conv4_filter, kernel_size=(9, 9), strides=(1, 1),\n",
    "                        padding='same', data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                        kernel_regularizer=l2(ridge),\n",
    "                        kernel_initializer=k_init, bias_initializer='zeros'))                                                                                                   \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, kernel_initializer=k_init,kernel_regularizer=l2(ridge)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=k_init,kernel_regularizer=l2(ridge)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256, kernel_initializer=k_init,kernel_regularizer=l2(ridge)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(CLASSES, kernel_initializer=k_init,kernel_regularizer=l2(ridge)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "Lr = 1e-4 \n",
    "dcy = 1e-6                                                                                                                                                                                \n",
    "m = 0.5\n",
    "# sgd = SGD(lr=Lr, momentum=m, decay=dcy,  nesterov=True)\n",
    "adam = Adam(lr=Lr, decay=dcy)\n",
    "\n",
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "print('learning rate: %f, decay: %f' %(Lr, dcy))\n",
    "\n",
    "from keras.backend import get_session\n",
    "get_session().run(tf.global_variables_initializer())\n",
    "a = model.fit(xtrain, ytrain, batch_size = 5, epochs= 10, verbose = 1)\n",
    "\n",
    "loss_and_metrics = model.evaluate(xval, yval, batch_size=5)\n",
    "\n",
    "print \"Loss and accuracy: \", loss_and_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
