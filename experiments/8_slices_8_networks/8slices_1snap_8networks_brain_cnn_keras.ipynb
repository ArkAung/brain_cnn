{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras implementation of Brain CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH = 64\n",
    "IMG_HEIGHT = 64\n",
    "SNAPS = 8\n",
    "\n",
    "SLICE = 5\n",
    "CLASSES = 2\n",
    "CHANNELS = 1\n",
    "\n",
    "conv1_filter = 4\n",
    "conv2_filter = 8\n",
    "conv3_filter = 16\n",
    "conv4_filter = 32\n",
    "conv5_filter = 4\n",
    "conv6_filter = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment = '1snap3d'\n",
    "path = '/work/aaung/datasets/' + experiment + '/'\n",
    "\n",
    "_04847_img = np.load(path + '4847_' + experiment + '-image.npy')\n",
    "_04799_img = np.load(path + '4799_' + experiment + '-image.npy')\n",
    "_04820_img = np.load(path + '4820_' + experiment + '-image.npy')\n",
    "_05675_img = np.load(path + '5675_' + experiment + '-image.npy')\n",
    "_05680_img = np.load(path + '5680_' + experiment + '-image.npy')\n",
    "_05710_img = np.load(path + '5710_' + experiment + '-image.npy')\n",
    "\n",
    "_04847_lbl = np.load(path + '4847_' + experiment + '-label-onehot.npy')\n",
    "_04799_lbl = np.load(path + '4799_' + experiment + '-label-onehot.npy')\n",
    "_04820_lbl = np.load(path + '4820_' + experiment + '-label-onehot.npy')\n",
    "_05675_lbl = np.load(path + '5675_' + experiment + '-label-onehot.npy')\n",
    "_05680_lbl = np.load(path + '5680_' + experiment + '-label-onehot.npy')\n",
    "_05710_lbl = np.load(path + '5710_' + experiment + '-label-onehot.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave on example out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a5328905af0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# n = 24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_04847_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_04799_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_04820_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_05675_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_05680_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_05710_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_lbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_04847_lbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_04799_lbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_04820_lbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_05675_lbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_05680_lbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_05710_lbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_04847_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_04799_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_04820_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_05675_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_05680_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_05710_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_lbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_04847_lbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_04799_lbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_04820_lbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_05675_lbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_05680_lbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_05710_lbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "# n = 24\n",
    "train_img = np.vstack((_04847_img[n:,], _04799_img[n:,], _04820_img[n:,], _05675_img[n:,], _05680_img[n:,], _05710_img[n:,]))\n",
    "train_lbl = np.vstack((_04847_lbl[n:,], _04799_lbl[n:,], _04820_lbl[n:,], _05675_lbl[n:,], _05680_lbl[n:,], _05710_lbl[n:,]))\n",
    "val_img = np.vstack((_04847_img[:n,], _04799_img[:n,], _04820_img[:n,], _05675_img[:n,], _05680_img[:n,], _05710_img[:n,]))\n",
    "val_lbl = np.vstack((_04847_lbl[:n,], _04799_lbl[:n,], _04820_lbl[:n,], _05675_lbl[:n,], _05680_lbl[:n,], _05710_lbl[:n,]))\n",
    "\n",
    "# Cross Subject\n",
    "# train_img = np.vstack((_05710_img, _04847_img, _04799_img, _05675_img, _05680_img))\n",
    "# train_lbl = np.vstack((_05710_lbl, _04847_lbl, _04799_lbl, _05675_lbl, _05680_lbl))\n",
    "# val_img =  _04820_img\n",
    "# val_lbl =  _04820_lbl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STRIP_HEIGHT = train_img.shape[2]\n",
    "STRIP_WIDTH = train_img.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_img.shape\n",
    "print val_img.shape\n",
    "print train_lbl.shape\n",
    "print val_lbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "# shuffle = np.random.permutation(database.shape[0])\n",
    "\n",
    "# test = database[shuffle[0:100],:]\n",
    "# val = database[shuffle[100:200],:]\n",
    "# train = database[shuffle[200:],:]\n",
    "\n",
    "xtrain = train_img[:,SLICE,:,:]\n",
    "xtrain = np.reshape(xtrain, (xtrain.shape[0], xtrain.shape[1], xtrain.shape[2], 1))\n",
    "ytrain = train_lbl\n",
    "\n",
    "xval = val_img[:,SLICE,:,:]\n",
    "xval = np.reshape(xval, (xval.shape[0], xval.shape[1], xval.shape[2], 1))\n",
    "yval = val_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print xtrain.shape\n",
    "print ytrain.shape\n",
    "print xval.shape\n",
    "print yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(5):\n",
    "    plt.show(plt.imshow(xtrain[i,:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EvaluateValidation(Callback):      \n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nValidation loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Model ###                                                                                                                               \n",
    "model = Sequential()\n",
    "mde = 0                                                                                                                                                                      \n",
    "k_init = 'he_normal'\n",
    "ridge = 0.0005\n",
    "\n",
    "model.add(Convolution2D(conv1_filter, kernel_size=(3, 3), strides=(1, 1),\n",
    "                        padding='same', data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                        kernel_regularizer=l2(ridge),\n",
    "                        kernel_initializer=k_init, bias_initializer='zeros', input_shape=(STRIP_HEIGHT, STRIP_WIDTH, CHANNELS)))                                                                                                   \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(conv2_filter, kernel_size=(5, 5), strides=(1, 1),\n",
    "                        padding='same', data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                        kernel_regularizer=l2(ridge),\n",
    "                        kernel_initializer=k_init, bias_initializer='zeros'))                                                                                                   \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "model.add(Convolution2D(conv3_filter, kernel_size=(7, 7), strides=(1, 1),\n",
    "                        padding='same', data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                        kernel_regularizer=l2(ridge),\n",
    "                        kernel_initializer=k_init, bias_initializer='zeros'))                                                                                                   \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(conv4_filter, kernel_size=(9, 9), strides=(1, 1),\n",
    "                        padding='same', data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                        kernel_regularizer=l2(ridge),\n",
    "                        kernel_initializer=k_init, bias_initializer='zeros'))                                                                                                   \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, kernel_initializer=k_init,kernel_regularizer=l2(ridge)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=k_init,kernel_regularizer=l2(ridge)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256, kernel_initializer=k_init,kernel_regularizer=l2(ridge)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(CLASSES, kernel_initializer=k_init,kernel_regularizer=l2(ridge)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "Lr = 1e-4 \n",
    "dcy = 1e-5                                                                                                                                                                                \n",
    "m = 0.5\n",
    "batch_sz = 25\n",
    "epoch = 25\n",
    "# sgd = SGD(lr=Lr, momentum=m, decay=dcy,  nesterov=True)\n",
    "adam = Adam(lr=Lr, decay=dcy)\n",
    "\n",
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "print('learning rate: %f, decay: %f' %(Lr, dcy))\n",
    "\n",
    "\n",
    "from keras.backend import get_session\n",
    "get_session().run(tf.global_variables_initializer())\n",
    "a = model.fit(xtrain, ytrain, batch_size = batch_sz, epochs= epoch, verbose = 1,\n",
    "              callbacks=[EvaluateValidation((xval, yval))])\n",
    "\n",
    "loss_and_metrics = model.evaluate(xval, yval, batch_size=batch_sz)\n",
    "\n",
    "print \"Loss and accuracy: \", loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_one_hot = model.predict(xval, batch_size=128)\n",
    "y_pred = np.argmax(y_pred_one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true = np.argmax(yval, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Test loss: {}\".format(loss_and_metrics[0])\n",
    "print \"Test Acc: {} %\".format(loss_and_metrics[1] * 100)\n",
    "print \"Precision\", sklearn.metrics.precision_score(y_true, y_pred)\n",
    "print \"Recall\", sklearn.metrics.recall_score(y_true, y_pred)\n",
    "print \"f1_score\", sklearn.metrics.f1_score(y_true, y_pred)\n",
    "print \"confusion_matrix\"\n",
    "print sklearn.metrics.confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "fpr, tpr, tresholds = sklearn.metrics.roc_curve(y_true, y_pred)\n",
    "ras = sklearn.metrics.auc(fpr, tpr)\n",
    "roauc_score = sklearn.metrics.roc_auc_score(y_true, y_pred)\n",
    "print ras\n",
    "print roauc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"{}\".format(loss_and_metrics[0])\n",
    "print \"{}\".format(loss_and_metrics[1] * 100)\n",
    "print sklearn.metrics.precision_score(y_true, y_pred)\n",
    "print sklearn.metrics.recall_score(y_true, y_pred)\n",
    "print sklearn.metrics.f1_score(y_true, y_pred)\n",
    "print sklearn.metrics.confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "n_classes = 2\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = sklearn.metrics.roc_curve(yval[:, i], y_pred_one_hot[:, i])\n",
    "    roc_auc[i] = sklearn.metrics.auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = sklearn.metrics.roc_curve(yval.ravel(), y_pred_one_hot.ravel())\n",
    "roc_auc[\"micro\"] = sklearn.metrics.auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "roauc_score = sklearn.metrics.roc_auc_score(y_true, y_pred)\n",
    "\n",
    "print roauc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[\"micro\"])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC classifying Faces of class {} (Pure class {} vs Mixed class {})'.format(CLASS, CLASS, CLASS))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print tpr[\"micro\"]\n",
    "print fpr[\"micro\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
