{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras implementation of Brain CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_DIM = 64\n",
    "SNAPS = 8 ##Number of snaps over 4 seconds\n",
    "STRIP_DEPTH = 8\n",
    "STRIP_WIDTH = 42 * SNAPS\n",
    "STRIP_HEIGHT = 51 * STRIP_DEPTH\n",
    "SLICE = 1\n",
    "CHANNELS = 1\n",
    "CLASSES = 2\n",
    "conv1_filter = 4\n",
    "conv2_filter = 8\n",
    "conv3_filter = 8\n",
    "conv4_filter = 8\n",
    "conv5_filter = 32\n",
    "conv6_filter = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment = 's8snap'\n",
    "path = './datasets/' + experiment + '/'\n",
    "\n",
    "_04847_img = np.load(path + '4847_' + experiment + '-image.npy')\n",
    "_04799_img = np.load(path + '4799_' + experiment + '-image.npy')\n",
    "_04820_img = np.load(path + '4820_' + experiment + '-image.npy')\n",
    "_05675_img = np.load(path + '5675_' + experiment + '-image.npy')\n",
    "_05680_img = np.load(path + '5680_' + experiment + '-image.npy')\n",
    "_05710_img = np.load(path + '5710_' + experiment + '-image.npy')\n",
    "\n",
    "_04847_lbl = np.load(path + '4847_' + experiment + '-label-onehot.npy')\n",
    "_04799_lbl = np.load(path + '4799_' + experiment + '-label-onehot.npy')\n",
    "_04820_lbl = np.load(path + '4820_' + experiment + '-label-onehot.npy')\n",
    "_05675_lbl = np.load(path + '5675_' + experiment + '-label-onehot.npy')\n",
    "_05680_lbl = np.load(path + '5680_' + experiment + '-label-onehot.npy')\n",
    "_05710_lbl = np.load(path + '5710_' + experiment + '-label-onehot.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave on example out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_img = np.vstack((_04847_img[5:,], _04799_img[5:,], _04820_img[5:,], _05675_img[5:,], _05680_img[5:,]))\n",
    "train_lbl = np.vstack((_04847_lbl[5:,], _04799_lbl[5:,], _04820_lbl[5:,], _05675_lbl[5:,], _05680_lbl[5:,]))\n",
    "val_img = np.vstack((_04847_img[:5,], _04799_img[:5,], _04820_img[:5,], _05675_img[:5,], _05680_img[:5,]))\n",
    "val_lbl = np.vstack((_04847_lbl[:5,], _04799_lbl[:5,], _04820_lbl[:5,], _05675_lbl[:5,], _05680_lbl[:5,]))\n",
    "\n",
    "# n = 10\n",
    "# train_img = np.vstack((_04847_img[n:,], _04799_img[n:,], _04820_img[n:,], _05675_img[n:,], _05680_img[n:,], _05710_img[n:,]))\n",
    "# train_lbl = np.vstack((_04847_lbl[n:,], _04799_lbl[n:,], _04820_lbl[n:,], _05675_lbl[n:,], _05680_lbl[n:,], _05710_lbl[n:,]))\n",
    "# val_img = np.vstack((_04847_img[:n,], _04799_img[:n,], _04820_img[:n,], _05675_img[:n,], _05680_img[:n,], _05710_img[:n,]))\n",
    "# val_lbl = np.vstack((_04847_lbl[:n,], _04799_lbl[:n,], _04820_lbl[:n,], _05675_lbl[:n,], _05680_lbl[:n,], _05710_img[:n,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.imshow(xtrain[1,:,:,0])\n",
    "# print xtrain[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 408, 336, 4)       40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 408, 336, 4)       16        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 408, 336, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 408, 336, 8)       808       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 408, 336, 8)       32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 408, 336, 8)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 204, 168, 8)       0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 872\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n",
      "learning rate: 0.000100, decay: 0.000001\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model target: expected max_pooling2d_1 to have 4 dimensions, but got array with shape (375, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8254f6bc7083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mloss_and_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aaung/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/aaung/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1407\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aaung/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1298\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m                                     exception_prefix='model target')\n\u001b[0m\u001b[1;32m   1301\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1302\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/home/aaung/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model target: expected max_pooling2d_1 to have 4 dimensions, but got array with shape (375, 2)"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# shuffle = np.random.permutation(database.shape[0])\n",
    "\n",
    "# test = database[shuffle[0:100],:]\n",
    "# val = database[shuffle[100:200],:]\n",
    "# train = database[shuffle[200:],:]\n",
    "\n",
    "xtrain = np.reshape(train_img, (train_img.shape[0], train_img.shape[1], train_img.shape[2], 1))\n",
    "ytrain = train_lbl\n",
    "\n",
    "xval = np.reshape(val_img, (val_img.shape[0], val_img.shape[1], val_img.shape[2], 1))\n",
    "yval = val_lbl\n",
    "\n",
    "### Model ###                                                                                                                               \n",
    "model = Sequential()\n",
    "mde = 0                                                                                                                                                                      \n",
    "k_init = 'he_normal'\n",
    "ridge = 0.0001\n",
    "\n",
    "model.add(Convolution2D(conv1_filter, kernel_size=(3, 3), strides=(1, 1),\n",
    "                        padding='same', data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                        kernel_regularizer=l2(ridge),\n",
    "                        kernel_initializer=k_init, bias_initializer='zeros', input_shape=(STRIP_HEIGHT, STRIP_WIDTH, CHANNELS)))                                                                                                   \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(conv2_filter, kernel_size=(5, 5), strides=(1, 1),\n",
    "                        padding='same', data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                        kernel_regularizer=l2(ridge),\n",
    "                        kernel_initializer=k_init, bias_initializer='zeros'))                                                                                                   \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides=2, padding='valid'))\n",
    "\n",
    "# model.add(Convolution2D(conv3_filter, kernel_size=(7, 7), strides=(1, 1),\n",
    "#                         padding='same', data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "#                         kernel_regularizer=l2(ridge),\n",
    "#                         kernel_initializer=k_init, bias_initializer='zeros'))                                                                                                   \n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Convolution2D(conv4_filter, kernel_size=(9, 9), strides=(1, 1),\n",
    "#                         padding='same', data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "#                         kernel_regularizer=l2(ridge),\n",
    "#                         kernel_initializer=k_init, bias_initializer='zeros'))                                                                                                   \n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(MaxPooling2D(pool_size = (2, 2), strides=2, padding='valid'))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1024, kernel_initializer=k_init,kernel_regularizer=l2(ridge)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(512, kernel_initializer=k_init,kernel_regularizer=l2(ridge)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(256, kernel_initializer=k_init,kernel_regularizer=l2(ridge)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(CLASSES, kernel_initializer=k_init,kernel_regularizer=l2(ridge)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "Lr = 1e-4 \n",
    "dcy = 1e-6                                                                                                                                                                                \n",
    "m = 0.5\n",
    "# sgd = SGD(lr=Lr, momentum=m, decay=dcy,  nesterov=True)\n",
    "adam = Adam(lr=Lr, decay=dcy)\n",
    "\n",
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "print('learning rate: %f, decay: %f' %(Lr, dcy))\n",
    "\n",
    "from keras.backend import get_session\n",
    "get_session().run(tf.global_variables_initializer())\n",
    "a = model.fit(xtrain, ytrain, batch_size = 5, epochs= 100, verbose = 1)\n",
    "\n",
    "loss_and_metrics = model.evaluate(xval, yval, batch_size=5)\n",
    "\n",
    "print \"Loss and accuracy: \", loss_and_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
